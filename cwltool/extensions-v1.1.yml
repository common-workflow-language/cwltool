$base: http://commonwl.org/cwltool#
$namespaces:
  cwl: "https://w3id.org/cwl/cwl#"
  cwltool: "http://commonwl.org/cwltool#"
$graph:
- $import: https://w3id.org/cwl/CommonWorkflowLanguage.yml

- name: Secrets
  type: record
  inVocab: false
  extends: cwl:ProcessRequirement
  fields:
    class:
      type: string
      doc: "Always 'Secrets'"
      jsonldPredicate:
        "_id": "@type"
        "_type": "@vocab"
    secrets:
      type: string[]
      doc: |
        List one or more input parameters that are sensitive (such as passwords)
        which will be deliberately obscured from logging.
      jsonldPredicate:
        "_type": "@id"
        refScope: 0


- name: ProcessGenerator
  type: record
  inVocab: true
  extends: cwl:Process
  documentRoot: true
  fields:
    - name: class
      jsonldPredicate:
        "_id": "@type"
        "_type": "@vocab"
      type: string
    - name: run
      type: [string, cwl:Process]
      jsonldPredicate:
        _id: "cwl:run"
        _type: "@id"
        subscope: run
      doc: |
        Specifies the process to run.

- name: MPIRequirement
  type: record
  inVocab: false
  extends: cwl:ProcessRequirement
  doc: |
    Indicates that a process requires an MPI runtime.
  fields:
    - name: class
      type: string
      doc: "Always 'MPIRequirement'"
      jsonldPredicate:
        "_id": "@type"
        "_type": "@vocab"
    - name: processes
      type: [int, cwl:Expression]
      doc: |
        The number of MPI processes to start. If you give a string,
        this will be evaluated as a CWL Expression and it must
        evaluate to an integer.

- name: CUDARequirement
  type: record
  extends: cwl:ProcessRequirement
  inVocab: false
  doc: |
    Require support for NVIDA CUDA (GPU hardware acceleration).
  fields:
    class:
      type: string
      doc: 'cwltool:CUDARequirement'
      jsonldPredicate:
        _id: "@type"
        _type: "@vocab"
    cudaVersionMin:
      type: string
      doc: |
        Minimum CUDA version to run the software, in X.Y format.  This
        corresponds to a CUDA SDK release.  When running directly on
        the host (not in a container) the host must have a compatible
        CUDA SDK (matching the exact version, or, starting with CUDA
        11.3, matching major version).  When run in a container, the
        container image should provide the CUDA runtime, and the host
        driver is injected into the container.  In this case, because
        CUDA drivers are backwards compatible, it is possible to
        use an older SDK with a newer driver across major versions.

        See https://docs.nvidia.com/deploy/cuda-compatibility/ for
        details.
    cudaComputeCapability:
      type:
        - 'string'
        - 'string[]'
      doc: |
        CUDA hardware capability required to run the software, in X.Y
        format.

        * If this is a single value, it defines only the minimum
          compute capability.  GPUs with higher capability are also
          accepted.

        * If it is an array value, then only select GPUs with compute
          capabilities that explicitly appear in the array.
    cudaDeviceCountMin:
      type: ['null', int, cwl:Expression]
      default: 1
      doc: |
        Minimum number of GPU devices to request.  If not specified,
        same as `cudaDeviceCountMax`.  If neither are specified,
        default 1.
    cudaDeviceCountMax:
      type: ['null', int, cwl:Expression]
      doc: |
        Maximum number of GPU devices to request.  If not specified,
        same as `cudaDeviceCountMin`.
